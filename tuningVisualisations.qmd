---
title: "Model Tuning"
format: html
---

# A document to aid visualisation

```{r preamble, echo = FALSE, warning=FALSE, message=FALSE}

if(!require(car)){install.packages("car")}
if(!require(psych)){install.packages("psych")}
if(!require(multcomp)){install.packages("multcomp")}
if(!require(emmeans)){install.packages("emmeans")}
if(!require(quantreg)){install.packages("quantreg")}
if(!require(FSA)){install.packages("FSA")}
if(!require(phia)){install.packages("phia")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(haven)){install.packages("haven")}
if(!require(plotly)){install.packages("plotly")}
if(!require(DBI)){install.packages("DBI")}
if(!require(RMariaDB)){install.packages("RMariaDB")}

library(car)
library(psych)
library(multcomp)
library(emmeans)
library(quantreg)
library(FSA)
library(phia)
library(tidyverse)
library(haven)
library(plotly)
library(DBI)
library(RMariaDB)

## DB Connection

database_connection <- read.csv("./code/mysqlDB/database_connection.csv")

dbName = database_connection$Value[1]
dbUsername = database_connection$Value[2]
dbPassword = database_connection$Value[3]
dbHostname = database_connection$Value[4]
dbPort = 3306

myDB <- dbConnect(MariaDB(), user = dbUsername, password = dbPassword, dbname = dbName, host = dbHostname, port = dbPort)

query = "SELECT * FROM modelstuning;"

models <- dbGetQuery(myDB, query)

dbDisconnect(myDB)

model_tests <- read.csv("./data/tuningTesting.csv")

models_joined <- inner_join(models, model_tests, by = "modelID")

models <- transmute(models_joined, 
                    modelID = haven::as_factor(modelID),
                    modelName = paste0("Neurons: ", neurons, " + Layers: ", layers),
                    modelName = haven::as_factor(modelName),
                    activationFunction = haven::as_factor(actfunc),
                    optimiser = haven::as_factor(optimiser),
                    batchsize = haven::as_factor(batchsize),
                    endAccuracy = as.numeric(endAccuracy)
                    )

mean_plot <- ggplot(models, aes(x = modelName, y = endAccuracy, fill = modelName)) +
geom_violin() + #geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5, stackratio = 0) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position="none") 

act_plot <- ggplot(models, aes(x = activationFunction, y = endAccuracy, fill = activationFunction)) +
geom_violin() + #geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5, stackratio = 0) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position="none") 

batch_plot <- ggplot(models, aes(x = batchsize, y = endAccuracy, fill = batchsize)) +
geom_violin() + #geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5, stackratio = 0) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position="none") 

opt_plot <- ggplot(models, aes(x = optimiser, y = endAccuracy, fill = optimiser)) +
geom_violin() + #geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5, stackratio = 0) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position="none") 

```

Here is a table of the final accuracies averaged for the four architectures, 1 layer, 2 layers, 4 layers, and 8 layers:

```{r final accuracy table, echo=FALSE, warning=FALSE, message=FALSE}

models_summarised <- models %>% group_by(activationFunction, batchsize, optimiser) %>%
  summarise(`Mean Accuracy` = mean(endAccuracy),
            `Median Accuracy` = median(endAccuracy),
            `Min Accuracy` = min(endAccuracy),
            `Max Accuracy` = max(endAccuracy)) %>% arrange(`Mean Accuracy`)

DT::datatable(models_summarised)

```

Mean accuracy by model-type

```{r mean_plot, echo = FALSE, warning=FALSE, message=FALSE}

ggplotly(mean_plot)

```

Mean accuracy by activation function

```{r act_plot, echo = FALSE, warning=FALSE, message=FALSE}

ggplotly(act_plot)

```

Mean accuracy by batch size

```{r batch_plot, echo = FALSE, warning=FALSE, message=FALSE}

ggplotly(batch_plot)

```

Mean accuracy by optimiser

```{r opt_plot, echo = FALSE, warning=FALSE, message=FALSE}

ggplotly(opt_plot)

```

```{r basic anova, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}

#Now let's explore these variables:

model_firstorder <- lm(endAccuracy ~ activationFunction + optimiser + batchsize + modelName,
           data = models)

print(Anova(model_firstorder,
      type = "II"))

```


```{r basic anova residuals, echo = FALSE, warning = FALSE, message = FALSE, eval=FALSE}

#The residuals are not normally distributed:

model_firstorder.residuals <- residuals(model_firstorder)

qqnorm(y = model_firstorder.residuals)

```

Let's use a more robust method, quantile regression on the conditional median:

```{r quantile regression, echo = FALSE, warning = FALSE, message = FALSE, eval=FALSE}

#Let's use a more robust method, quantile regression on the conditional median:
model_rq <- rq(endAccuracy ~ activationFunction + optimiser + batchsize + modelName,
           data = models, tau = seq(0, 1, by = 0.1))

model_rq

summary(model_rq)

```

